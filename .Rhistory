print(my_lucky_number)
# Import numpy for using mean function
import numpy as np
heights_in_cm = [185, 190, 178, 192, 188, 176, 180]
#Calculate of average of heights
average = np.mean(heights_in_cm)
# Print the value of variable
print("the average of heights:", average)
# Import numpy for using mean function
import numpy as np
heights_in_cm = [185, 190, 178, 192, 188, 176, 180]
#Calculate of average of heights
average = rounde(np.mean(heights_in_cm,4)
# Print the value of variable
print("the average of heights:", average)
# Import numpy for using mean function
import numpy as np
heights_in_cm = [185, 190, 178, 192, 188, 176, 180]
#Calculate of average of heights
average = np.mean(heights_in_cm)
# Print the value of variable
print("the average of heights:", average)
quit
vector <- c(25, 36, 121,9)
#Calculate square roots of elements
square_roots <- sqrt(vector)
#Print the list of square roots
cat("square_roots:", square_roots)
reticulate::repl_python()
list = [25, 36, 121,9]
square_roots = []
#Calculate square roots and add the list of them
for i in list:
square_roots.append(i**0.5)
#Print the list of square roots
print("square_roots:", square_roots)
# Import the “na_example” data set
library(dslabs)
data("na_example")
#Print the data set
na_example
# Count the total number of NA
total_number_NA1 <- sum(is.na(na_example))
cat("TOTAL NUMBER OF NA :", total_number_NA1 )
# Create new variable for data set with 0
na_example_with_0 <- na_example
# Replace NAs with 0
na_example_with_0[is.na(na_example)] <- 0
# Print new data set with 0
na_example_with_0
# Count the total number of NA in new data set
total_number_NA2 <- sum(is.na(na_example_with_0))
cat("TOTAL NUMBER OF NA :", total_number_NA2 )
# Import the “na_example” data set
library(dslabs)
data("na_example")
#Print the data set
na_example
# Count the total number of NA
total_number_NA1 <- sum(is.na(na_example))
cat("TOTAL NUMBER OF NA :", total_number_NA1 )
reticulate::repl_python()
list = [25, 36, 121,9]
square_roots = []
#Calculate square roots and add the list of them
for i in list:
square_roots.append(i**0.5)
#Print the list of square roots
print("square_roots:", square_roots)
quit
vector <- c(25, 36, 121,9)
#Calculate square roots of elements
square_roots <- sqrt(vector)
#Print the list of square roots
cat("square_roots:", square_roots)
reticulate::repl_python()
# Import numpy for using mean function
import numpy as np
# Create a list of heights in cm
heights_in_cm = [185, 190, 178, 192, 188, 176, 180]
# Calculate the average of the heights using np.mean()
average = np.mean(heights_in_cm)
# Print the value of the average
print("The average of heights is:", average)
# Import numpy for using mean function
import numpy as np
heights_in_cm = [185, 190, 178, 192, 188, 176, 180]
#Calculate of average of heights
average = np.mean(heights_in_cm)
# Print the value of variable
print("the average of heights:", average)
quit
reticulate::repl_python()
# Import numpy for using mean function
import numpy as np
heights_in_cm = [185, 190, 178, 192, 188, 176, 180]
#Calculate of average of heights
average = np.mean(heights_in_cm)
# Print the value of variable
print("the average of heights:", average)
list = [25, 36, 121,9]
square_roots = []
#Calculate square roots and add the list of them
for i in list:
square_roots.append(i**0.5)
#Print the list of square roots
print("square_roots:", square_roots)
# Assign the value of 7 to the variable 'my_lucky_number'
my_lucky_number = 7
#Update the value of 'my_lucky_number'
my_lucky_number += 2
# Print the new value of variable 'my_lucky_number'
print(my_lucky_number)
quit
# Assign the value of 7 which is my lucky number to the variable 'my_lucky_number'
my_lucky_number <- 7
#Update the value of 'my_lucky_number'
my_lucky_number <- my_lucky_number + 2
# Print the new value of variable 'my_lucky_number'
print(my_lucky_number)
heights_in_cm <- c(185,190, 178, 192, 188, 176, 180)
average <- mean(heights_in_cm)
cat("the average of heights:", average)
reticulate::repl_python()
# Import numpy for using mean function
import numpy as np
heights_in_cm = [185, 190, 178, 192, 188, 176, 180]
#Calculate of average of heights
average = np.mean(heights_in_cm)
# Print the value of variable
print("the average of heights:", average)
quit
reticulate::repl_python()
# Import numpy for using mean function
import numpy as np
# Create a list of heights in cm
heights_in_cm = [185, 190, 178, 192, 188, 176, 180]
# Calculate the average of the heights using np.mean()
average = np.mean(heights_in_cm)
# Print the value of the average to the console
print("The average of heights is:", average)
quit
reticulate::repl_python()
# Import numpy for using mean function
# Create a list of heights in cm
heights_in_cm = [185, 190, 178, 192, 188, 176, 180]
# Calculate the average of the heights using np.mean()
average = heights_in_cm
# Print the value of the average to the console
print("The average of heights is:", average)
quit
reticulate::repl_python()
# Import numpy for using mean function
import numpy as np
heights_in_cm = [185, 190, 178, 192, 188, 176, 180]
#Calculate of average of heights
average = np.mean(heights_in_cm)
# Print the value of variable
print("the average of heights:", average)
x <- 1
x
# Import the “na_example” data set
library(dslabs)
data("na_example")
#Print the data set
na_example
# Count the total number of NA
total_number_NA1 <- sum(is.na(na_example))
cat("TOTAL NUMBER OF NA :", total_number_NA1 )
# Create new variable for data set with 0
na_example_with_0 <- na_example
# Replace NAs with 0
na_example_with_0[is.na(na_example)] <- 0
# Print new data set with 0
na_example_with_0
# Count the total number of NA in new data set
total_number_NA2 <- sum(is.na(na_example_with_0))
cat("TOTAL NUMBER OF NA :", total_number_NA2 )
install.packages("thestats")
library(thestats)
data(thestats)
data(thestats)
install.packages("thestats")
install.packages("thestats")
library(thestats)
library(thestats)
data(thestats)
load("C:/Users/huawei/Downloads/depts_en.rda")
load("C:/Users/huawei/Desktop/depts_en.rda")
library(tidyverse)
library(stringr)
library(rvest)
library(ggplot2)
url_2010_2023 <- "https://www.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-31&num_votes=2500,&country_of_origin=TR&count=250"
url_before_2010 <- "https://www.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250"
url_vector <- c(url_2010_2023, url_before_2010)
titles <- c()
years <- c()
durations <- c()
ratings <- c()
votes <- c()
for (url in url_vector) {
page <- read_html(url)
title_names <- page %>% html_nodes('.ipc-title__text') %>% html_text()
title_names <- tail(head(title_names, -1), -1)
title_names <- str_split(title_names, " ", n = 2)
title_names <- unlist(lapply(title_names, function(x) {x[2]}))
year <- page %>% html_nodes(".sc-43986a27-7.dBkaPT.dli-title-metadata") %>% html_text() %>%
substr(1, 4) %>%
as.numeric()
duration <- page %>% html_nodes(".sc-43986a27-7.dBkaPT.dli-title-metadata") %>% html_text()
hour <- str_extract(duration, "\\d+h") %>%
str_replace("h", "") %>%
as.numeric() %% 10
total_duration <- hour * 60 + str_extract(duration, "\\d+m") %>%
str_replace("m", "") %>%
as.numeric()
rating <- page %>% html_nodes(".ipc-rating-star.ipc-rating-star--base.ipc-rating-star--imdb.ratingGroup--imdb-rating") %>%
html_text() %>%
substr(1, 3) %>%
as.numeric()
vote <- page %>% html_node(".sc-53c98e73-0.kRnqtn") %>% html_text() %>%
parse_number()
titles <- append(titles, title_names)
years <- append(years, year)
durations <- append(durations, total_duration)
ratings <- append(ratings, rating)
votes <- append(votes, vote)
}
movies <- data.frame(titles, years, durations, ratings, votes)
print(head(movies))
movies %>% arrange(desc(ratings))
movies_desc_order <- movies %>% arrange(desc(ratings))
View(movies_desc_order)
# Descending order by rating of movies
movies_desc_order <- movies %>% arrange(desc(ratings))
# The top 5 of movies
print(head(movies_desc_order,n=5)
# The bottom 5 of movies
print(tail(movies_desc_order,n=5)
# The top 5 of movies
print(head(movies_desc_order,n=5))
# The bottom 5 of movies
print(tail(movies_desc_order,n=5))
fav_movies <- ("Babam ve Oglum","Selvi Boylum Al Yazmalim","G.O.R.A.")
fav_movies <- c("Babam ve Oglum","Selvi Boylum Al Yazmalim","G.O.R.A.")
# Check the features for my favorite movies
fav_movies_features <- movies %>% filter (titles %in% fav_movies)
fav_movies_features
# Check the features for my favorite movies
fav_movies_features <- movies %>% filter (titles %in% fav_movies) %>% select(-durations)
fav_movies_features
fav_movies_features <- movies %>% filter (titles %in% fav_movies) %>% select(-durations) %>% arrange(desc(ratings))
rating <- page %>% html_nodes(".ipc-rating-star.ipc-rating-star--base.ipc-rating-star--imdb.ratingGroup--imdb-rating") %>%
html_text() %>%
substr(1, 3) %>%
as.numeric()
fav_movies_features
fav_movies <- ("Babam ve Oglum","Selvi Boylum Al Yazmalim","G.O.R.A.")
fav_movies <- c("Babam ve Oglum","Selvi Boylum Al Yazmalim","G.O.R.A.")
# Check the years, rating and votes for my favorite movies
fav_movies <- movies %>% filter (titles %in% fav_movies) %>% select(-durations) %>% arrange(desc(ratings))
print(fav_movies)
# Descending order by rating of movies
movies_desc_order <- movies %>% arrange(desc(ratings))
# The top 5 of movies
print(head(movies_desc_order,n=5)
# Descending order by rating of movies
movies_desc_order <- movies %>% arrange(desc(ratings))
# The top 5 of movies
print(head(movies_desc_order,n=5))
# The bottom 5 of movies
print(tail(movies_desc_order,n=5))
# Import necessary packages
library(tidyverse)
library(stringr)
library(rvest)
library(ggplot2)
# Generate the Urls vector
url_2010_2023 <- "https://www.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-31&num_votes=2500,&country_of_origin=TR&count=250"
url_before_2010 <- "https://www.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250"
url_vector <- c(url_2010_2023, url_before_2010)
library(tidyverse)
library(stringr)
library(rvest)
url_2010_2023 <- "https://www.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-31&num_votes=2500,&country_of_origin=TR&count=250"
url_before_2010 <- "https://www.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250"
url_vector <- c(url_2010_2023, url_before_2010)
# Generate vectors for title, year,duration, rating, votes variables
titles <- c()
years <- c()
durations <- c()
ratings <- c()
votes <- c()
# Use For Loop for reading the HTML content of IBMD website because of having two dimensional vector of Urls
for (url in url_vector) {
page <- read_html(url)
# Web scrapping to create a Data Frame with columns: Title, Year, Duration, Rating, Votes
title_names <- page %>% html_nodes('.ipc-title__text') %>% html_text()
title_names <- tail(head(title_names, -1), -1)
title_names <- str_split(title_names, " ", n = 2)
title_names <- unlist(lapply(title_names, function(x) {x[2]}))
year <- page %>% html_nodes(".sc-43986a27-7.dBkaPT.dli-title-metadata") %>% html_text() %>%
substr(1, 4) %>%
as.numeric()
duration <- page %>% html_nodes(".sc-43986a27-7.dBkaPT.dli-title-metadata") %>% html_text()
# Extract only the hour part from the data containing both time and date, divide the data by 10 and take the        remainder
hour <- str_extract(duration, "\\d+h") %>%
str_replace("h", "") %>%
as.numeric() %% 10
total_duration <- hour * 60 + str_extract(duration, "\\d+m") %>%
str_replace("m", "") %>%
as.numeric()
rating <- page %>% html_nodes(".ipc-rating-star.ipc-rating-star--base.ipc-rating-star--imdb.ratingGroup--imdb-rating") %>%
html_text() %>%
substr(1, 3) %>%
as.numeric()
vote <- page %>% html_node(".sc-53c98e73-0.kRnqtn") %>% html_text() %>%
parse_number()
# Adding URLs to the vectors created initially is done using the append function
titles <- append(titles, title_names)
years <- append(years, year)
durations <- append(durations, total_duration)
ratings <- append(ratings, rating)
votes <- append(votes, vote)
}
# Generate Data Frame with columns: Title, Year, Duration, Rating, Votes
movies <- data.frame(titles, years, durations, ratings, votes)
print(head(movies))
library(tidyverse)
library(stringr)
library(rvest)
library(ggplot2)
url_2010_2023 <- "https://www.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-31&num_votes=2500,&country_of_origin=TR&count=250"
url_before_2010 <- "https://www.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250"
url_vector <- c(url_2010_2023, url_before_2010)
titles <- c()
years <- c()
durations <- c()
ratings <- c()
votes <- c()
for (url in url_vector) {
page <- read_html(url)
title_names <- page %>% html_nodes('.ipc-title__text') %>% html_text()
title_names <- tail(head(title_names, -1), -1)
title_names <- str_split(title_names, " ", n = 2)
title_names <- unlist(lapply(title_names, function(x) {x[2]}))
year <- page %>% html_nodes(".sc-43986a27-7.dBkaPT.dli-title-metadata") %>% html_text() %>%
substr(1, 4) %>%
as.numeric()
duration <- page %>% html_nodes(".sc-43986a27-7.dBkaPT.dli-title-metadata") %>% html_text()
hour <- str_extract(duration, "\\d+h") %>%
str_replace("h", "") %>%
as.numeric() %% 10
total_duration <- hour * 60 + str_extract(duration, "\\d+m") %>%
str_replace("m", "") %>%
as.numeric()
rating <- page %>% html_nodes(".ipc-rating-star.ipc-rating-star--base.ipc-rating-star--imdb.ratingGroup--imdb-rating") %>%
html_text() %>%
substr(1, 3) %>%
as.numeric()
vote <- page %>% html_node(".sc-53c98e73-0.kRnqtn") %>% html_text() %>%
parse_number()
titles <- append(titles, title_names)
years <- append(years, year)
durations <- append(durations, total_duration)
ratings <- append(ratings, rating)
votes <- append(votes, vote)
}
movies <- data.frame(titles, years, durations, ratings, votes)
print(head(movies))
library(tidyverse)
library(stringr)
library(rvest)
url_2010_2023 <- "https://www.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-31&num_votes=2500,&country_of_origin=TR&count=250"
url_before_2010 <- "https://www.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250"
url_vector <- c(url_2010_2023, url_before_2010)
# Generate vectors for title, year,duration, rating, votes variables
titles <- c()
years <- c()
durations <- c()
ratings <- c()
votes <- c()
# Use For Loop for reading the HTML content of IBMD website because of having two dimensional vector of Urls
for (url in url_vector) {
page <- read_html(url)
# Web scrapping to create a Data Frame with columns: Title, Year, Duration, Rating, Votes
title_names <- page %>% html_nodes('.ipc-title__text') %>% html_text()
title_names <- tail(head(title_names, -1), -1)
title_names <- str_split(title_names, " ", n = 2)
title_names <- unlist(lapply(title_names, function(x) {x[2]}))
year <- page %>% html_nodes(".sc-43986a27-7.dBkaPT.dli-title-metadata") %>% html_text() %>%
substr(1, 4) %>%
as.numeric()
duration <- page %>% html_nodes(".sc-43986a27-7.dBkaPT.dli-title-metadata") %>% html_text()
# Extract only the hour part from the data containing both time and date, divide the data by 10 and take the        remainder
hour <- str_extract(duration, "\\d+h") %>%
str_replace("h", "") %>%
as.numeric() %% 10
total_duration <- hour * 60 + str_extract(duration, "\\d+m") %>%
str_replace("m", "") %>%
as.numeric()
rating <- page %>% html_nodes(".ipc-rating-star.ipc-rating-star--base.ipc-rating-star--imdb.ratingGroup--imdb-rating") %>%
html_text() %>%
substr(1, 3) %>%
as.numeric()
vote <- page %>% html_node(".sc-53c98e73-0.kRnqtn") %>% html_text() %>%
parse_number()
# Adding URLs to the vectors created initially is done using the append function
titles <- append(titles, title_names)
years <- append(years, year)
durations <- append(durations, total_duration)
ratings <- append(ratings, rating)
votes <- append(votes, vote)
}
# Generate Data Frame with columns: Title, Year, Duration, Rating, Votes
movies <- data.frame(titles, years, durations, ratings, votes)
print(head(movies))
library(tidyverse)
library(stringr)
library(rvest)
url_2010_2023 <- "https://www.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-31&num_votes=2500,&country_of_origin=TR&count=250"
url_before_2010 <- "https://www.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250"
url_vector <- c(url_2010_2023, url_before_2010)
# Generate vectors for title, year,duration, rating, votes variables
titles <- c()
years <- c()
durations <- c()
ratings <- c()
votes <- c()
# Use For Loop for reading the HTML content of IBMD website because of having two dimensional vector of Urls
for (url in url_vector) {
page <- read_html(url)
# Web scrapping to create a Data Frame with columns: Title, Year, Duration, Rating, Votes
title_names <- page %>% html_nodes('.ipc-title__text') %>% html_text()
title_names <- tail(head(title_names, -1), -1)
title_names <- str_split(title_names, " ", n = 2)
title_names <- unlist(lapply(title_names, function(x) {x[2]}))
year <- page %>% html_nodes(".sc-43986a27-7.dBkaPT.dli-title-metadata") %>% html_text() %>%
substr(1, 4) %>%
as.numeric()
duration <- page %>% html_nodes(".sc-43986a27-7.dBkaPT.dli-title-metadata") %>% html_text()
# Extract only the hour part from the data containing both time and date, divide the data by 10 and take the        remainder
hour <- str_extract(duration, "\\d+h") %>%
str_replace("h", "") %>%
as.numeric() %% 10
total_duration <- hour * 60 + str_extract(duration, "\\d+m") %>%
str_replace("m", "") %>%
as.numeric()
rating <- page %>% html_nodes(".ipc-rating-star.ipc-rating-star--base.ipc-rating-star--imdb.ratingGroup--imdb-rating") %>%
html_text() %>%
substr(1, 3) %>%
as.numeric()
vote <- page %>% html_node(".sc-53c98e73-0.kRnqtn") %>% html_text() %>%
parse_number()
# Adding URLs to the vectors created initially is done using the append function
titles <- append(titles, title_names)
years <- append(years, year)
durations <- append(durations, total_duration)
ratings <- append(ratings, rating)
votes <- append(votes, vote)
}
# Generate Data Frame with columns: Title, Year, Duration, Rating, Votes
movies <- data.frame(titles, years, durations, ratings, votes)
print(head(movies))
library(tidyverse)
library(stringr)
library(rvest)
url_2010_2023 <- "https://www.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-31&num_votes=2500,&country_of_origin=TR&count=250"
url_before_2010 <- "https://www.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250"
url_vector <- c(url_2010_2023, url_before_2010)
# Generate vectors for title, year,duration, rating, votes variables
titles <- c()
years <- c()
durations <- c()
ratings <- c()
votes <- c()
# Use For Loop for reading the HTML content of IBMD website because of having two dimensional vector of Urls
for (url in url_vector) {
page <- read_html(url)
# Web scrapping to create a Data Frame with columns: Title, Year, Duration, Rating, Votes
title_names <- page %>% html_nodes('.ipc-title__text') %>% html_text()
title_names <- tail(head(title_names, -1), -1)
title_names <- str_split(title_names, " ", n = 2)
title_names <- unlist(lapply(title_names, function(x) {x[2]}))
year <- page %>% html_nodes(".sc-43986a27-7.dBkaPT.dli-title-metadata") %>% html_text() %>%
substr(1, 4) %>%
as.numeric()
duration <- page %>% html_nodes(".sc-43986a27-7.dBkaPT.dli-title-metadata") %>% html_text()
# Extract only the hour part from the data containing both time and date, divide the data by 10 and take the        remainder
hour <- str_extract(duration, "\\d+h") %>%
str_replace("h", "") %>%
as.numeric() %% 10
total_duration <- hour * 60 + str_extract(duration, "\\d+m") %>%
str_replace("m", "") %>%
as.numeric()
rating <- page %>% html_nodes(".ipc-rating-star.ipc-rating-star--base.ipc-rating-star--imdb.ratingGroup--imdb-rating") %>%
html_text() %>%
substr(1, 3) %>%
as.numeric()
vote <- page %>% html_node(".sc-53c98e73-0.kRnqtn") %>% html_text() %>%
parse_number()
# Adding URLs to the vectors created initially is done using the append function
titles <- append(titles, title_names)
years <- append(years, year)
durations <- append(durations, total_duration)
ratings <- append(ratings, rating)
votes <- append(votes, vote)
}
# Generate Data Frame with columns: Title, Year, Duration, Rating, Votes
movies <- data.frame(titles, years, durations, ratings, votes)
print(head(movies))
